{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import split_data_to_traj_and_control, mat2tracks\n",
    "import wandb\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mat_path = \"./matlab/sdreDataset.mat\"\n",
    "val_mat_path = \"./matlab/sdreVal.mat\"\n",
    "\n",
    "train = scipy.io.loadmat(train_mat_path)[\"dataset\"]\n",
    "val = scipy.io.loadmat(val_mat_path)[\"sdreVal\"]\n",
    "\n",
    "reshape = True\n",
    "train_tracks = mat2tracks(train, reshape=reshape)\n",
    "val_tracks = mat2tracks(val, reshape=reshape)\n",
    "\n",
    "train_tracks = np.vstack(train_tracks) \n",
    "val_tracks = np.vstack(val_tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20200, 10100)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = split_data_to_traj_and_control(train_tracks)\n",
    "test_dataset = split_data_to_traj_and_control(val_tracks)\n",
    "len(train_dataset), len(val_tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, \n",
    "                          batch_size=64, \n",
    "                          shuffle=True,\n",
    "                          drop_last=True)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, \n",
    "                          batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import DummyModel2\n",
    "from train_utils import train_epoch, eval_epoch\n",
    "from models import SplittedModel, SplittedModel2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SplittedModel2(\n",
       "  (block1): SplittedModelBlock2(\n",
       "    (fc1): Linear(in_features=2, out_features=32, bias=True)\n",
       "    (fc2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (fc3): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (act): ReLU()\n",
       "  )\n",
       "  (block2): SplittedModelBlock2(\n",
       "    (fc1): Linear(in_features=2, out_features=32, bias=True)\n",
       "    (fc2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (fc3): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (act): ReLU()\n",
       "  )\n",
       "  (block3): SplittedModelBlock2(\n",
       "    (fc1): Linear(in_features=2, out_features=32, bias=True)\n",
       "    (fc2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (fc3): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (act): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hidden_dim_1 = 64\n",
    "# hidden_dim_2 = 64\n",
    "# dropout_rate = 0.\n",
    "# model = DummyModel2(hidden_dim_1=hidden_dim_1, \n",
    "#                    hidden_dim_2=hidden_dim_2, \n",
    "#                    dropout_rate=dropout_rate)\n",
    "\n",
    "\n",
    "# hidden_dim_1 = 64\n",
    "# model = SplittedModel(hidden_dim_1=hidden_dim_1)\n",
    "\n",
    "hidden_dim_1 = 16\n",
    "hidden_dim_2 = 16\n",
    "model = SplittedModel2(hidden_dim_1=hidden_dim_1, hidden_dim_2=hidden_dim_2)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "criteria = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:du0bbvk8) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>val_loss</td><td>█▅▅▂▂▂▂▂▄▁▂▂▂▂▂▂▂▂▂▁▁▁▂▁▂▂▁▁▁▁▂▁▁▁▂▃▁▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>149</td></tr><tr><td>val_loss</td><td>0.00823</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Orig split; Splitted Model, hidden_dim=16,16</strong> at: <a href='https://wandb.ai/petili/SDRE_Approx/runs/du0bbvk8' target=\"_blank\">https://wandb.ai/petili/SDRE_Approx/runs/du0bbvk8</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230510_202841-du0bbvk8\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:du0bbvk8). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c47027270945417a9ad8c383c93904dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\petry\\Desktop\\МФТИ\\МТИИ-Учеба\\2 семестр\\Проект Управление\\wandb\\run-20230510_203115-hhbomru9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/petili/SDRE_Approx/runs/hhbomru9' target=\"_blank\">Orig split; Splitted Model, hidden_dim=32,32</a></strong> to <a href='https://wandb.ai/petili/SDRE_Approx' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/petili/SDRE_Approx' target=\"_blank\">https://wandb.ai/petili/SDRE_Approx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/petili/SDRE_Approx/runs/hhbomru9' target=\"_blank\">https://wandb.ai/petili/SDRE_Approx/runs/hhbomru9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb_loggging = True\n",
    "\n",
    "if wandb_loggging:\n",
    "    project_name = \"SDRE_Approx\"\n",
    "    # run_name = f\"Orig split; MLP 6-{hidden_dim_1}-{hidden_dim_2}-3, dropout={dropout_rate}\"\n",
    "    # run_name = f\"Orig split; Splitted Model, hidden_dim={hidden_dim_1}\"\n",
    "    run_name = f\"Orig split; Splitted Model, hidden_dim={hidden_dim_1},{hidden_dim_2}\"\n",
    "    wandb.login()\n",
    "    wandb.init(project=project_name,\n",
    "               name=run_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improve eval losss on epoch 0 =  tensor(0.0106)\n",
      "Improve eval losss on epoch 1 =  tensor(0.0076)\n",
      "Improve eval losss on epoch 2 =  tensor(0.0067)\n",
      "Improve eval losss on epoch 3 =  tensor(0.0064)\n",
      "Improve eval losss on epoch 4 =  tensor(0.0062)\n",
      "Improve eval losss on epoch 5 =  tensor(0.0060)\n",
      "Improve eval losss on epoch 7 =  tensor(0.0060)\n",
      "Improve eval losss on epoch 9 =  tensor(0.0058)\n",
      "Improve eval losss on epoch 12 =  tensor(0.0057)\n",
      "Improve eval losss on epoch 20 =  tensor(0.0057)\n",
      "Improve eval losss on epoch 21 =  tensor(0.0057)\n",
      "Improve eval losss on epoch 28 =  tensor(0.0056)\n",
      "Improve eval losss on epoch 43 =  tensor(0.0056)\n",
      "Improve eval losss on epoch 47 =  tensor(0.0056)\n",
      "Improve eval losss on epoch 54 =  tensor(0.0056)\n",
      "Improve eval losss on epoch 87 =  tensor(0.0056)\n",
      "Improve eval losss on epoch 93 =  tensor(0.0056)\n",
      "Improve eval losss on epoch 108 =  tensor(0.0056)\n",
      "Improve eval losss on epoch 127 =  tensor(0.0055)\n"
     ]
    }
   ],
   "source": [
    "best_loss = 1e6\n",
    "# save_path = f\"MLP_3_{hidden_dim_1}_{hidden_dim_2}_6_best.pth\"\n",
    "save_path = f\"splitted_model_best.pth\"\n",
    "\n",
    "for epoch in range(150):\n",
    "# for epoch in range(100, 300):\n",
    "    train_epoch(model, device, train_loader, criteria, optimizer)\n",
    "    val_loss = eval_epoch(model, device, test_loader, criteria)\n",
    "    \n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        # torch.save(model.state_dict(), save_path)\n",
    "        print(f\"Improve eval losss on epoch {epoch} = \", best_loss)\n",
    "        \n",
    "    if wandb_loggging:\n",
    "        wandb.log({\n",
    "            \"val_loss\": val_loss,\n",
    "            \"epoch\" : epoch\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
